## Теоретические основы поэлементных преобразований изображений (по вашему коду)

### 1. Введение в обработку изображений

**Цифровое изображение** – это, по сути, двумерный массив (матрица), где каждый элемент (пиксель) хранит информацию о яркости или цвете в соответствующей точке изображения.
**Поэлементные (точечные) преобразования** – это операции, при которых новое значение каждого пикселя зависит *только* от его исходного значения (и, возможно, от глобальных характеристик изображения, но не от значений соседних пикселей). Это один из простейших, но фундаментальных классов операций в обработке изображений.

### 2. Начальные шаги: Чтение и преобразование изображения

*   **Чтение изображения (`cv2.imread`)**:
    *   Библиотека OpenCV (cv2) предоставляет функцию `imread` для загрузки изображения из файла. Изображение загружается как массив NumPy.
    *   Цветные изображения обычно загружаются в формате BGR (синий, зеленый, красный), а не в более привычном RGB. Поэтому часто требуется конвертация.

*   **Преобразование в градации серого (`cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)`)**:
    *   **Цветное изображение (RGB)**: Каждый пиксель описывается тремя значениями (интенсивность красного, зеленого и синего каналов).
    *   **Изображение в градациях серого (Grayscale)**: Каждый пиксель описывается одним значением – уровнем яркости (интенсивности). Обычно это целое число от 0 (черный) до 255 (белый).
    *   **Зачем преобразовывать?**
        *   Уменьшение объема данных и сложности вычислений.
        *   Многие алгоритмы анализа и обработки (например, выделение контуров, пороговая обработка, анализ текстур) изначально разработаны для монохромных изображений или более эффективно работают с ними. Информация о цвете не всегда необходима для решения задачи.
    *   **Как происходит преобразование?** Существует несколько формул. Распространенная формула для преобразования RGB в яркость (Luminance, Y) учитывает разную чувствительность человеческого глаза к разным цветам:
        \[ Y = 0.299 \cdot R + 0.587 \cdot G + 0.114 \cdot B \]
        OpenCV использует подобную формулу.

### 3. Функция поэлементной обработки `fun(image, prepfun)`

*   Эта функция является ядром многих ваших операций. Ее структура `fun(Image, prepfun)` очень важна:
    *   `Image`: Входное изображение (в вашем случае, серое).
    *   `prepfun` (**функция препарирования**): Это функция, которая определяет, как будет преобразовано *каждое отдельное значение пикселя*. Она принимает одно значение яркости пикселя на вход и возвращает новое значение яркости.
*   **Принцип работы `fun`**:
    1.  Создается копия входного изображения, чтобы не изменять оригинал.
    2.  Происходит итерация по каждому пикселю изображения (по строкам и столбцам).
    3.  Для каждого пикселя `image[i, j]`:
        *   Берется его текущее значение яркости `pixel_value`.
        *   Это значение передается в `prepfun`: `new_value = prepfun(pixel_value)`.
        *   Полученное `new_value` записывается в соответствующий пиксель выходного изображения.
        *   `np.clip(new_value, 0, 255)`: Важный шаг, который гарантирует, что новое значение яркости останется в допустимом диапазоне \[0, 255]. Если `prepfun` вернет значение, например, -10 или 300, `clip` "обрежет" его до 0 или 255 соответственно.
*   **Универсальность**: Прелесть такой структуры в том, что вы можете реализовать множество различных преобразований, просто написав разные функции `prepfun`. Примеры в вашем коде: `invert_pixel`, `manual_threshold`, `contrast_stretch_pixel`, лямбда-функция для LUT при эквализации, `piecewise_linear_prep`.

### 4. Гистограмма яркости

*   **Определение**: Гистограмма яркости изображения – это график, который показывает, сколько пикселей в изображении имеют каждый из возможных уровней яркости.
    *   По оси X откладываются уровни яркости (например, от 0 до 255).
    *   По оси Y откладывается количество пикселей (или их доля/вероятность), имеющих данный уровень яркости.
*   **Построение (`cv2.calcHist`, `plt.hist`)**:
    *   `cv2.calcHist`: Функция OpenCV, специально предназначенная для вычисления гистограмм. Она может работать с многоканальными изображениями, масками и различными диапазонами.
    *   `plt.hist` из Matplotlib: Также может строить гистограммы, часто используется для быстрой визуализации распределений данных из массивов NumPy.
*   **Что показывает гистограмма?**
    *   **Общий контраст**: Если гистограмма сосредоточена в узком диапазоне, изображение, вероятно, низкоконтрастное. Если пики разнесены по всему диапазону – высококонтрастное.
    *   **Распределение яркостей**: Преобладание темных (пики слева), светлых (пики справа) или средних тонов.
    *   **Наличие объектов и фона**: Если объект и фон имеют существенно разные яркости, на гистограмме могут быть видны два или более отдельных пика, разделенных "долиной". Это используется для выбора порога.
*   **Нормализованная гистограмма**: Иногда гистограмму нормализуют, деля значения каждого бина на общее число пикселей. Тогда по оси Y откладывается не количество пикселей, а их доля (или оценка плотности вероятности уровня яркости).

### 5. Пороговая обработка (Бинаризация)

*   **Цель**: Упростить изображение, разделив все пиксели на два класса: объект (обычно белый, 255) и фон (обычно черный, 0), или наоборот. Это достигается путем выбора **порогового значения (T)**.
*   **Математическая формулировка**: Для каждого пикселя `f(x,y)`:
    \[ g(x,y) = \begin{cases} V_{max} & \text{if } f(x,y) > T \\ V_{min} & \text{if } f(x,y) \le T \end{cases} \]
    Где `V_max` обычно 255, а `V_min` обычно 0.

*   **4. Ручная пороговая обработка**:
    *   **Выбор порога**: Порог `T` выбирается "на глаз" на основе анализа гистограммы. Идеально, если на гистограмме есть два четких пика (соответствующих объекту и фону), и порог выбирается в "долине" между ними.
    *   **Реализация**: Ваша функция `manual_threshold(pixel_value, threshold)` и затем `fun(img_gray, threshold_func)`.

*   **5. Пороговая обработка методом Оцу (`cv2.threshold(..., cv2.THRESH_OTSU)`)**:
    *   **Определение**: Автоматический метод определения оптимального порога для бинаризации. Он особенно хорошо работает для изображений с бимодальной гистограммой (два пика).
    *   **Принцип работы**: Метод Оцу ищет такой порог `T`, который минимизирует взвешенную внутриклассовую дисперсию (или, что эквивалентно, максимизирует межклассовую дисперсию).
        *   **Внутриклассовая дисперсия**: Мера "разбросанности" значений яркости пикселей внутри каждого из двух классов (объект и фон), образованных порогом. Метод стремится сделать каждый класс как можно более "однородным" по яркости.
        *   Для каждого возможного порога `T` (от 0 до 255), метод делит пиксели на два класса. Затем вычисляет дисперсию яркостей для пикселей ниже порога и для пикселей выше порога. Оптимальный порог `T` тот, для которого взвешенная сумма этих двух дисперсий минимальна.
    *   **Преимущества**: Автоматизация, не требует ручного подбора. Часто дает хорошие результаты для подходящих изображений.
    *   **Ограничения**: Может плохо работать на изображениях с сильно несбалансированными размерами классов, унимодальной гистограммой или сильным шумом.

### 6. Линейное контрастирование

*   **Динамический диапазон изображения**: Разница между максимальным (`f_max`) и минимальным (`f_min`) значениями яркости пикселей в изображении. Если этот диапазон узок (например, все яркости лежат между 50 и 100), изображение выглядит блеклым, низкоконтрастным.
*   **Цель**: Растянуть исходный динамический диапазон `[f_min, f_max]` на новый, обычно полный `[new_min, new_max]` (например, \[0, 255]), чтобы улучшить визуальный контраст.
*   **Функция препарирования (линейное преобразование)**:
    \[ g(f) = a \cdot f + b \]
    где `f` – исходная яркость, `g(f)` – новая яркость.
*   **Расчет коэффициентов `a` и `b`**:
    Мы хотим, чтобы:
    1.  `f_min` отобразился в `new_min`: `new_min = a \cdot f_min + b`
    2.  `f_max` отобразился в `new_max`: `new_max = a \cdot f_max + b`

    Это система из двух линейных уравнений с двумя неизвестными `a` и `b`.
    *   **Вычисление `a` (коэффициент масштабирования, наклон прямой)**:
        Вычтем (1) из (2):
        `new_max - new_min = a \cdot f_max - a \cdot f_min = a \cdot (f_max - f_min)`
        Отсюда:
        \[ a = \frac{new\_max - new\_min}{f\_max - f\_min} \]
        *   `a > 1`: Растяжение контраста (если `new_max - new_min > f_max - f_min`).
        *   `0 < a < 1`: Сжатие контраста.
        *   `a < 0`: Инверсия и растяжение/сжатие.
        *   **Важно**: Если `f_max == f_min` (все пиксели имеют одну яркость), знаменатель равен нулю. В вашем коде это обрабатывается присвоением `a = 0` (или `a=1`, в зависимости от желаемого поведения). Если `a=0`, то `g(f) = b`, т.е. все пиксели станут `new_min`.

    *   **Вычисление `b` (коэффициент сдвига, смещение по оси Y)**:
        Из уравнения (1):
        \[ b = new\_min - a \cdot f\_min \]
        Этот коэффициент сдвигает масштабированную яркость так, чтобы минимальное значение соответствовало `new_min`.
*   **Реализация**: Ваша функция `linear_contrast_stretching` и вложенная `contrast_stretch_pixel`.

### 7. Эквализация гистограммы (Выравнивание гистограммы)

*   **Цель**: Преобразовать изображение таким образом, чтобы его гистограмма стала как можно более равномерной (в идеале – плоской). Это обычно приводит к значительному увеличению глобального контраста, делая видимыми детали, которые были скрыты из-за плохого распределения яркостей.
*   **Основная идея**: Использовать кумулятивную функцию распределения (CDF) исходной гистограммы как функцию преобразования.
    *   **Гистограмма (PDF - Probability Density Function)**: Для каждого уровня яркости `r_k` (где `k` от 0 до `L-1`, `L=256`), `p(r_k) = n_k / N`, где `n_k` – количество пикселей с яркостью `r_k`, `N` – общее число пикселей.
    *   **Кумулятивная функция распределения (CDF)**:
        \[ s_k = T(r_k) = \sum_{j=0}^{k} p(r_j) \]
        Значение `s_k` – это вероятность того, что пиксель будет иметь яркость меньшую или равную `r_k`. CDF монотонно возрастает от 0 до 1.
        В вашем коде `cdf = hist.cumsum()` вычисляет кумулятивную сумму частот, а не вероятностей, но это масштабируется на следующем шаге.

*   **Формула преобразования (для отображения в диапазон \[0, L-1])**:
    \[ g_k = (L-1) \cdot s_k = (L-1) \cdot \sum_{j=0}^{k} \frac{n_j}{N} \]
    В вашем коде используется несколько модифицированная версия для улучшения результата, особенно для дискретных гистограмм:
    \[ \text{new\_value} = \text{round} \left( \frac{cdf(v) - cdf_{min}}{N - cdf_{min}} \cdot (L-1) \right) \]
    где:
    *   `cdf(v)`: значение кумулятивной суммы для уровня яркости `v` (из `hist.cumsum()`).
    *   `cdf_min`: минимальное *ненулевое* значение в `cdf`. Вычитание `cdf_min` помогает нормализовать CDF так, чтобы даже самые темные области исходного изображения (имеющие `cdf(v) = cdf_min`) отобразились в 0, а не в какое-то большее значение. Это обеспечивает использование всего выходного диапазона.
    *   `N` (в вашем коде `total_pixels`): общее количество пикселей.
    *   `L-1` (в вашем коде 255): максимальный уровень яркости.
*   **LUT (Look-Up Table)**: Вместо того чтобы вычислять это преобразование для каждого пикселя заново, создается таблица поиска (`cdf_normalized_lut`). Индекс этой таблицы – это исходная яркость пикселя (0-255), а значение по этому индексу – новая (эквализованная) яркость. Это значительно ускоряет процесс.
    `prep_fun = lambda p_val: cdf_normalized_lut[p_val]` – это и есть применение LUT.
*   **Результат**: Изображение с более "растянутой" и равномерной гистограммой.

### 8. Адаптивная эквализация гистограммы CLAHE

*   **Проблема глобальной эквализации**: Глобальная эквализация (как описано выше) применяет одно и то же преобразование ко всему изображению. Это может быть проблематично:
    *   Если в изображении есть области с очень разной освещенностью, глобальное преобразование может улучшить контраст в одних областях за счет ухудшения в других.
    *   В областях с низкой локальной вариацией (например, почти однородный фон) эквализация может чрезмерно усилить шум.
*   **CLAHE (Contrast Limited Adaptive Histogram Equalization)**: Адаптивный метод, который решает эти проблемы.
    *   **Адаптивность**: Изображение делится на небольшие неперекрывающиеся или частично перекрывающиеся регионы, называемые **тайлами (tiles)** (задается `tileGridSize`, например, (8,8)). Эквализация гистограммы выполняется для каждого тайла *независимо*. Это позволяет адаптировать преобразование к локальным характеристикам яркости.
    *   **Ограничение контраста (Contrast Limiting)**: Чтобы предотвратить чрезмерное усиление шума (что характерно для эквализации в областях с почти плоской гистограммой), гистограмма каждого тайла перед эквализацией **обрезается (клиппируется)** по заданному **пределу контрастности (`clipLimit`)**. Если какой-либо бин гистограммы превышает этот предел, "избыток" пикселей из этого бина перераспределяется равномерно по другим бинам гистограммы. Это сглаживает гистограмму и ограничивает усиление.
    *   **Интерполяция**: Чтобы избежать появления резких границ между тайлами на результирующем изображении, значения яркости пикселей вычисляются с помощью билинейной интерполяции на основе преобразований из четырех ближайших центров тайлов.
*   **Преимущества CLAHE**: Лучше сохраняет локальные детали, не так сильно усиливает шум, как глобальная эквализация, и хорошо подходит для изображений с неоднородным освещением.

### 9. Препарирование изображения с заданной препарирующей функцией (кусочно-линейная функция)

*   **Функция препарирования (общий термин)**: Как упоминалось, это любая функция `g = T(f)`, которая отображает входной уровень яркости `f` в выходной уровень `g`.
*   **Кусочно-линейная функция препарирования**:
    *   Это гибкий способ задать нелинейное преобразование яркости, определяя его поведение на отдельных участках диапазона.
    *   **Определение**: Функция задается набором **опорных точек** (`input_points`, `output_points`).
        *   `input_points = [x_0, x_1, ..., x_n]`: Массив X-координат (входные яркости).
        *   `output_points = [y_0, y_1, ..., y_n]`: Массив Y-координат (соответствующие им выходные яркости).
    *   **Принцип работы**:
        1.  Для корректной интерполяции входные точки (и соответствующие им выходные) сортируются по возрастанию X-координат.
        2.  Для любого входного значения яркости `pixel_value`, функция `np.interp(pixel_value, input_points_sorted, output_points_sorted)` находит два ближайших значения в `input_points_sorted`, скажем `x_i` и `x_{i+1}`, такие что `x_i <= pixel_value <= x_{i+1}`.
        3.  Затем, используя соответствующие `y_i` и `y_{i+1}` из `output_points_sorted`, она вычисляет новое значение по формуле линейной интерполяции (значение на отрезке прямой, соединяющей точки `(x_i, y_i)` и `(x_{i+1}, y_{i+1})`):
            \[ y = y_i + (pixel\_value - x_i) \cdot \frac{y_{i+1} - y_i}{x_{i+1} - x_i} \]
        4.  Если `pixel_value` выходит за пределы диапазона `input_points_sorted` (меньше `min(input_points_sorted)` или больше `max(input_points_sorted)`), `np.interp` экстраполирует, используя крайние значения `output_points_sorted` (т.е., если `pixel_value < x_0`, то `new_value = y_0`; если `pixel_value > x_n`, то `new_value = y_n`).
    *   **Пример ваших точек**:
        `input_points = [0, 63, 63, 127, 127, 191, 191, 255]`
        `output_points = [255,0,255,0,255,0,255,0]`
        *   Участок [0, 63] входных яркостей будет отображен в [255, 0] выходных (инверсия и сжатие в темную область).
        *   Наличие одинаковых `input_points` (например, `63, 63`) с разными `output_points` (0 и 255) создает **вертикальный разрыв** в функции препарирования. То есть, значение 63 может быть отображено либо в 0, либо в 255 в зависимости от того, как `np.interp` обрабатывает такие случаи (обычно это зависит от порядка точек или может привести к поведению, где одна из точек "перекрывает" другую, или используется среднее, но чаще это создает резкий скачок). В вашем коде, так как точки сортируются, поведение для `pixel_value = 63` будет зависеть от того, какая пара `(63,0)` или `(63,255)` окажется "активной" для интерполяции в этой точке или в непосредственной близости. График функции покажет это наглядно. Это создает эффект "пилы" или "волны".
*   **График препарирующей функции**: Визуализация этой функции (как в вашем коде с помощью `plt.plot`) очень важна, так как она наглядно показывает, как именно будут изменяться яркости пикселей.

### 10. Визуализация

*   **`matplotlib.pyplot`**: Используется для отображения изображений, гистограмм и графиков функций.
*   **`imshow`**: Отображает данные как изображение.
*   **`axis('off')`**: Убирает оси с цифрами, что более привычно для изображений.
*   **`tight_layout()`**: Автоматически корректирует параметры подграфиков для плотного их расположения.
*   **`show()`**: Отображает все созданные фигуры.

Эта теория должна покрыть основные аспекты вашего кода. Если какие-то моменты требуют более глубокого или другого объяснения, дайте знать!

